{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen, Request\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "import psycopg2 as pg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = ['voo','jpm','iipr','tgt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_sentiment_df(parsed_df):\n",
    "    mean_df = parsed_df.groupby(['Ticker','Date']).mean()\n",
    "    mean_df = mean_df.unstack()\n",
    "    mean_df = mean_df.xs(key='compound_score',axis = 1).transpose()\n",
    "    return mean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock_news_headline_parser_scraper(stock_ticker_list):\n",
    "    \n",
    "    website_url = 'https://finviz.com/quote.ashx?t='\n",
    "    news_tables = {}\n",
    "\n",
    "    for ticker in stock_ticker_list:\n",
    "\n",
    "        #URL for each stock\n",
    "        url = website_url + ticker\n",
    "\n",
    "        #requesting url for each ticker\n",
    "        response = urlopen(Request(url=url, headers={'user-agent': 'sentiment-analysis-app'}))\n",
    "\n",
    "        #html parser, using bs4. downloaded the html\n",
    "        html = BeautifulSoup(response,'html')\n",
    "\n",
    "        #the body that contains all the news article links\n",
    "        news_table_html_body = html.find(id = 'news-table')\n",
    "\n",
    "        #each stock is in dictionary with value corresponding to news table\n",
    "        news_tables.update({ticker:news_table_html_body})\n",
    "\n",
    "\n",
    "\n",
    "    parsed_data = []\n",
    "\n",
    "    #itterating over key and value pairs. itterating over a dict\n",
    "    for ticker, news_tables in news_tables.items():\n",
    "\n",
    "        # news_tables.find_all('tr') is bs4 list of all articles headlins\n",
    "        for row in news_tables.find_all('tr'):\n",
    "\n",
    "            #title is in acnchor tag 'a', retrieving that from bs4 obj row\n",
    "            title = row.a.text\n",
    "\n",
    "            #time stamps have td tags\n",
    "            timestamp = row.td.text\n",
    "\n",
    "            #no date information\n",
    "            if(len(timestamp.split(' ')) == 1):\n",
    "                time = timestamp.split(' ')[0]\n",
    "\n",
    "            #has date info, before time\n",
    "            else:\n",
    "                date = timestamp.split(' ')[0]\n",
    "                time = timestamp.split(' ')[1]\n",
    "\n",
    "            parsed_data.append([ticker,title,date,time])\n",
    "    #########\n",
    "        \n",
    "        df = pd.DataFrame(parsed_data,columns=['Ticker','Title','Date', 'Time'])\n",
    "        vader = SentimentIntensityAnalyzer()\n",
    "        df['Compound_score'] = df['Title'].apply(lambda title : vader.polarity_scores(title)['compound'] )\n",
    "\n",
    "        for i in df.index:\n",
    "            df.at[i, 'Time'] = df['Time'][i][0:7]\n",
    "            \n",
    "        df['Time'] = pd.to_datetime(df['Time']).dt.strftime('%H:%M:%S')\n",
    "        df['Date'] = pd.to_datetime(df.Date).dt.date\n",
    "        df = df.set_index('Date')\n",
    "    return df[['Time','Ticker','Compound_score','Title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = stock_news_headline_parser_scraper(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://postgres:postgres@localhost:5432/Stock_sentiment_analysis_data')\n",
    "new_df.to_sql('stock_news_sentiments', engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Saving to Database\n",
    "conn = pg2.connect(database='Stock_sentiment_analysis_data',user='postgres',password='postgres')\n",
    "cur = conn.cursor()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#avg_sentiment_df(stock_news_headline_parser_scraper(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
