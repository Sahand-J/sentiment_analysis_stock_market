{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Sun Feb 21 2021\n",
    "@author: Sahand-j\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import pandas_datareader,datetime\n",
    "import pandas_datareader.data as web\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date \n",
    "\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen, Request\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import yahoo_fin.stock_info as si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'tsla,aapl,iipr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock_prices_df(ticker_list):\n",
    "    \n",
    "    \"\"\"\n",
    "    Inserts each stock ticker price history into database\n",
    "    :@return(string): returns string confirming query execution\n",
    "    \"\"\"\n",
    "    \n",
    "    engine = create_engine('postgresql://postgres:postgres@localhost:5432/Stocks')\n",
    "\n",
    "    for i in ticker_list.split(','):\n",
    "        df = si.get_data(i)\n",
    "    \n",
    "        # Basic formatting\n",
    "        df = df[['ticker','open', 'high', 'low', 'close', 'adjclose', 'volume']]    \n",
    "        df = df.fillna(0)\n",
    "        df['updated'] = pd.to_datetime('now')\n",
    "        \n",
    "        # Resetting index for db\n",
    "        df.reset_index(inplace=True)\n",
    "        df = df.rename(columns = {'index':'date'})\n",
    "\n",
    "        # Write the data into the database\n",
    "        df.to_sql('stocks_daily_prices', engine, if_exists='append')\n",
    "\n",
    "    # Create a primary key on the table\n",
    "    query = \"\"\"ALTER TABLE stocks_daily_prices \n",
    "                ADD PRIMARY KEY (ticker,date);\"\"\"\n",
    "    engine.execute(query)\n",
    "\n",
    "    return 'query succesful'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stock_prices_df(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentiment analysis data \n",
    "\"\"\"\n",
    "    Inserts each stock ticker price history into database\n",
    "    :@return(string): returns string confirming query execution\n",
    "    \"\"\"\n",
    "\n",
    "def stock_news_headline_scraper(ticker_list):\n",
    "    \n",
    "    website_url = 'https://finviz.com/quote.ashx?t='\n",
    "    news_tables = {}\n",
    "    engine = create_engine('postgresql://postgres:postgres@localhost:5432/Stocks')\n",
    "\n",
    "    for ticker in ticker_list.split(','):\n",
    "\n",
    "        #URL for each stock\n",
    "        url = website_url + ticker\n",
    "\n",
    "        #requesting url for each ticker\n",
    "        response = urlopen(Request(url=url, headers={'user-agent': 'sentiment-analysis-app'}))\n",
    "\n",
    "        #html parser, using bs4. downloaded the html\n",
    "        html = BeautifulSoup(response,'html')\n",
    "\n",
    "        #the body that contains all the news article links\n",
    "        news_table_html_body = html.find(id = 'news-table')\n",
    "\n",
    "        #each stock is in dictionary with value corresponding to news table\n",
    "        news_tables.update({ ticker.upper() : news_table_html_body })\n",
    "\n",
    "\n",
    "    parsed_data = []\n",
    "\n",
    "    #itterating over key and value pairs. itterating over a dict\n",
    "    for ticker, news_tables in news_tables.items():\n",
    "\n",
    "        # news_tables.find_all('tr') is bs4 list of all articles headlins\n",
    "        for row in news_tables.find_all('tr'):\n",
    "\n",
    "            #title is in acnchor tag 'a', retrieving that from bs4 obj row\n",
    "            title = row.a.text\n",
    "\n",
    "            #time stamps have td tags\n",
    "            timestamp = row.td.text\n",
    "\n",
    "            #no date information\n",
    "            if(len(timestamp.split(' ')) == 1):\n",
    "                time = timestamp.split(' ')[0]\n",
    "\n",
    "            #has date info, before time\n",
    "            else:\n",
    "                date = timestamp.split(' ')[0]\n",
    "                time = timestamp.split(' ')[1]\n",
    "\n",
    "            parsed_data.append([ticker,title,date,time])\n",
    "        \n",
    "        \n",
    "        \n",
    "        df = pd.DataFrame(parsed_data,columns=['ticker','title','date','time'])\n",
    "        vader = SentimentIntensityAnalyzer()\n",
    "        \n",
    "        #compund score for each article title\n",
    "        df['comp_score'] = df['title'].apply(lambda title : vader.polarity_scores(title)['compound'])\n",
    "        \n",
    "        for i in df.index:\n",
    "            df.at[i, 'time'] = df['time'][i][0:7]\n",
    "        \n",
    "        #converting string time col to datetime obj   \n",
    "        df['time'] = pd.to_datetime(df['time']).dt.strftime('%H:%M:%S')\n",
    "        df['date'] = pd.to_datetime(df.date).dt.date\n",
    "        \n",
    "        #df = df.set_index('date')\n",
    "        df['updated'] = pd.to_datetime('now')\n",
    "        \n",
    "        #filterign nuetral news out of df\n",
    "        df = df[df.comp_score != 0]\n",
    "\n",
    "        df = df[['date','ticker','comp_score','title','updated']]\n",
    "        \n",
    "        # Write the data into the database\n",
    "        df.to_sql('stock_sentiments', engine, if_exists='append')\n",
    "\n",
    "    '''# Create a primary key on the table\n",
    "    query = \"\"\"ALTER TABLE stock_sentiments \n",
    "                ADD PRIMARY KEY (ticker, date, time);\"\"\"\n",
    "    \n",
    "    engine.execute(query) \n",
    "    #return df   '''\n",
    "    \n",
    "    return 'sentiment table created successfully'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_news_headline_scraper(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph stock price with sentiment\n",
    "'''\n",
    "query a join between stock price and sentiment on matching days\n",
    "create a view of this\n",
    "insert into df\n",
    "return df to plot\n",
    "\n",
    "plot df \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation analysis\n",
    "'''\n",
    "get df with stock price and sentiment score on days\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
