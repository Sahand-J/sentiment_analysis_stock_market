{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Sun Feb 21 2021\n",
    "@author: Sahand-j\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import pandas_datareader,datetime\n",
    "import pandas_datareader.data as web\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date \n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen, Request\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from sqlalchemy import create_engine\n",
    "import yahoo_fin.stock_info as si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'voo,vti,jpm,iipr,vt,vxus,tgt,dfs,schd,dgro,nobl,schb,spy,nsc,sdy,gm,unp,qqq,dis,land,aapl,stor,ko'\n",
    "s2 = 'tsla,amat,avgo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_ticker_list(ticker_list):\n",
    "    return ticker_list.upper().split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    webscrapes new stock headlines from finviz.com\n",
    "    :@return(dict): returns dictionary of stok tickers and their assoicated news headlines for availabe dates\n",
    "    \"\"\"\n",
    "\n",
    "def stock_headline_scraper_dict(ticker_list):\n",
    "    website_url = 'https://finviz.com/quote.ashx?t='\n",
    "    news_tables_dict = {}\n",
    "    \n",
    "    for ticker in ticker_list:\n",
    "\n",
    "        #URL for each stock\n",
    "        url = website_url + ticker\n",
    "\n",
    "        #requesting url for each ticker\n",
    "        response = urlopen(Request(url=url, headers={'user-agent': 'sentiment-analysis-app'}))\n",
    "\n",
    "        #html parser, using bs4. downloaded the html\n",
    "        html = BeautifulSoup(response,'html')\n",
    "\n",
    "        #the body that contains all the news article links\n",
    "        news_table_html_body = html.find(id = 'news-table')\n",
    "\n",
    "        #each stock is in dictionary with value corresponding to news table\n",
    "        news_tables_dict.update({ ticker.upper() : news_table_html_body })\n",
    "    return news_tables_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    takes in dictionary of stock tickers and their associated headlines \n",
    "    :@return(Dataframe): returns Dataframe of stock tickers, their assoicated news headlines, and sentiment score \n",
    "    \"\"\"\n",
    "\n",
    "def stock_sentiment_df(news_tables_dict):\n",
    "    \n",
    "    parsed_data = []\n",
    "    #itterating over key and value pairs. itterating over a dict\n",
    "    for ticker, news_tables_dict in news_tables_dict.items():\n",
    "        for row in news_tables_dict.find_all('tr'):\n",
    "\n",
    "            #title is in acnchor tag 'a', retrieving that from bs4 obj row\n",
    "            title = row.a.text\n",
    "\n",
    "            #time stamps have td tags\n",
    "            timestamp = row.td.text\n",
    "\n",
    "            #no date information\n",
    "            if(len(timestamp.split(' ')) == 1):\n",
    "                time = timestamp.split(' ')[0]\n",
    "\n",
    "            #has date info, before time\n",
    "            else:\n",
    "                date = timestamp.split(' ')[0]\n",
    "                time = timestamp.split(' ')[1]\n",
    "            parsed_data.append([ticker,title,date,time])\n",
    "\n",
    "        df = pd.DataFrame(parsed_data,columns=['ticker','title','date','time'])\n",
    "\n",
    "        #compund score for each article title\n",
    "        vader = SentimentIntensityAnalyzer()\n",
    "        df['comp_score'] = df['title'].apply(lambda title : vader.polarity_scores(title)['compound'])\n",
    "\n",
    "        for i in df.index:\n",
    "            df.at[i, 'time'] = df['time'][i][0:7]\n",
    "\n",
    "        #converting string time col to datetime obj   \n",
    "        df['time'] = pd.to_datetime(df['time']).dt.strftime('%H:%M:%S')\n",
    "        df['date'] = pd.to_datetime(df.date).dt.date\n",
    "\n",
    "        #df = df.set_index('date')\n",
    "        df['updated'] = pd.to_datetime('now')\n",
    "\n",
    "        #filtering nuetral news out of df\n",
    "        df = df[df.comp_score != 0]\n",
    "\n",
    "        #columns of interest\n",
    "        df = df[['date','ticker','comp_score','title','updated']]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://postgres:postgres@localhost:5432/Stocks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>comp_score</th>\n",
       "      <th>title</th>\n",
       "      <th>updated</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-06</th>\n",
       "      <td>VOO</td>\n",
       "      <td>0.3818</td>\n",
       "      <td>Whats Behind ETF Issuer Growth Gap</td>\n",
       "      <td>2021-02-24 02:48:36.363511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-04</th>\n",
       "      <td>VOO</td>\n",
       "      <td>0.5106</td>\n",
       "      <td>Record ETF Assets Growth In 2020</td>\n",
       "      <td>2021-02-24 02:48:36.363511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ticker  comp_score                               title  \\\n",
       "date                                                                \n",
       "2021-01-06    VOO      0.3818  Whats Behind ETF Issuer Growth Gap   \n",
       "2021-01-04    VOO      0.5106    Record ETF Assets Growth In 2020   \n",
       "\n",
       "                              updated  \n",
       "date                                   \n",
       "2021-01-06 2021-02-24 02:48:36.363511  \n",
       "2021-01-04 2021-02-24 02:48:36.363511  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#has datetime index\n",
    "df = stock_sentiment_df(stock_headline_scraper_dict(format_ticker_list(s)))\n",
    "df['date'] = pd.to_datetime(df.date)\n",
    "df.set_index('date',inplace=True)\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make this also updatale with new stock daily data\n",
    "#df.to_sql('stock_sentiments_data', engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading stock data\n",
    "def stock_prices_dict(ticker_list):\n",
    "    \n",
    "    \"\"\"\n",
    "    :@return(dict): returns dictionary of stock ticker with Dataframe values with stock historic price data\n",
    "    \"\"\"\n",
    "    \n",
    "    dict_of_dfs = {}\n",
    "    for i in ticker_list:\n",
    "        temp_df = si.get_data(i)  \n",
    "        temp_df['rolling_mean'] = temp_df['adjclose'].rolling(round(len(temp_df)*.15)).mean()\n",
    "        temp_df['rolling_std'] = temp_df['adjclose'].rolling(round(len(temp_df)*.15)).std()\n",
    "        temp_df['cumel_return'] = (1 + temp_df['adjclose'].pct_change(1)).cumprod()\n",
    "        temp_df['updated'] = pd.to_datetime('now')\n",
    "        dict_of_dfs.update({i.upper() : temp_df})\n",
    "    return dict_of_dfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datetime index\n",
    "#stock_prices_dict(format_ticker_list(s)).get('AVGO').head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#putting all available current web scraping data\n",
    "#in 'main_stock_sentiment_data' db table, this is master data \n",
    "df.to_sql('main_stock_sentiment_data', engine, if_exists='fail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "#new day to reitterate information. adding new info \n",
    "df2 = stock_sentiment_df(stock_headline_scraper_dict(format_ticker_list(s2)))\n",
    "\n",
    "check = engine.has_table('new_data_with_old')\n",
    "print(check)\n",
    "\n",
    "if check == True:\n",
    "    engine.execute('DROP TABLE new_data_with_old CASCADE;')\n",
    "    df2.to_sql('new_data_with_old', engine, if_exists='replace')\n",
    "else:\n",
    "    df2.to_sql('new_data_with_old', engine, if_exists='replace')\n",
    "    \n",
    "\n",
    "    \n",
    "view_query = '''\n",
    "\n",
    "create view new_sentiment_data_view as\n",
    "select\n",
    "new_data_with_old.date,\n",
    "new_data_with_old.ticker,\n",
    "new_data_with_old.comp_score,\n",
    "new_data_with_old.title,\n",
    "new_data_with_old.updated\n",
    "\n",
    "from new_data_with_old\n",
    "left join main_stock_sentiment_data ON\n",
    "new_data_with_old.date = main_stock_sentiment_data.date AND\n",
    "new_data_with_old.ticker = main_stock_sentiment_data.ticker AND\n",
    "new_data_with_old.title = main_stock_sentiment_data.title\n",
    "WHERE main_stock_sentiment_data.date IS null;\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "add_new_vals_to_senti_table_query = '''\n",
    "insert into main_stock_sentiment_data\n",
    "select *\n",
    "from new_sentiment_data_view;'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.execute(view_query);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.execute(add_new_vals_to_senti_table_query);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
